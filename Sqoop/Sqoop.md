<a href="https://github.com/och5351/cluster#readme">메인으로</a>

# Sqoop

Sqoop (SQL for Hadoop)은 관계형 데이터베이스(RDB)와 분산 파일 시스템(HDFS) 사이의 양방향 데이터 전송을 위해 설계된 툴이다. 오직 두 포인트 사이의 데이터 통신을 쉽게 다루기 위해서 개발된 프로젝트.

<a id="home1"></a>

## 목차

- [1. Sqoop](#1)
- [2. Sqoop 설치](#2)
- [3. 스쿱 커넥터](#3)
- [4. Sqoop Import](#4)

<br>

<a id="1"></a>

## 1. Sqoop

하둡 플랫폼의 강력함은 다양한 데이터 타입을 다룰 수 있다는데 있다. 하지만 HDFS 외부의 스토리지 저장소에 있는 데이터에 접근하려면 맵리듀스 프로그램은 외부 API를 이용해야 한다. 회사의 주요 데이터는 RDBMS와 같은 구조적인 데이터 저장소에 주로 저장되며, 아파치 스쿱은 구조화된 데이터 저장소에서 데이터를 추출해서 하둡으로 보내 처리할 수 있도록 해주는 오픈 소스 도구다.

<br>

<div align="right">

[목차로](#home1)

</div><br><br>
<a id="2"></a>

## 2. Sqoop 설치

<br>

> 스쿱 2는 스쿱 1의 구조적 한게를 해결하기 위해 개발. 스쿱 1은 명령행 도구고 자바 API를 제공하지 않았기 때문에 다른 프로그램에 내장하기 어려움. 또한 스쿱 1의 모든 커넥터는 모든 출력 포맷에 대한 정의를 포함해야 하므로 새로운 커넥터를 작성하는 것은 매우 어려움. 스쿱 2는 잡을 실행하는 서버 컴포넌트 뿐만 아니라 명령행 인터페이서(CLI), 웹 UI, REST API, 자바 API 등 다양한 클라이언트 제공.

> 스쿱 1은 안정적인 릴리즈 지원한다. 스쿱2의 개발은 매우 활발하나 스쿱 1과 비교했을 때 부족한 점이 일부 있다.

<br>

<div align="right">

[목차로](#home1)

</div><br><br>
<a id="3"></a>

## 3. Sqoop 커넥터
<br>

스쿱 커넥터는 이 프레임워크를 사용하여 스쿱이 임포트와 익스포트하게 해주는 모듈식 컴포넌트다. 스쿱은 MySQL, PostgreSQL, 오라클, SQL 서버, DB2, 네티자 등 다양한 관계형 데이터베이스에서 작동하는 커넥터를 제공한다. 또한 자바의 JDBC 프로토콜을 지원하는 어떤 데이터베이스에도 연결할 수 있도록 제네릭 JDBC 커넥터도 제공한다. couchbase 같은 NoSQL 저장소에서 대용량 전송이 가능하며, 내장 커넥터에는 없으므로 따로 내려 받아서 사용한다.

<br>

<div align="right">

[목차로](#home1)

</div><br><br>
<a id="4"></a>

## 4. Sqoop Import
<br>

스쿱의 import 도구는 맴리듀스 잡을 실행하여 대상 데이터베이스에 접속하고 테이블을 읽는다. 일반적으로 임포트 처리 성능을 향상시키기 위해 맴 테스크 4 개를 병렬로 실행할 것을 권장한다. 각 테스크는 임포트된 결과를 지정된 디렉터리 아래에 각각 다른 이름의 파일로 저장.

<br>

기본적으로 스쿱은 임포트한 데이터로 콤마로 구분된 텍스트 파일을 생성한다. 컬럼 구분자는 명시적으로 지정할 수 있으며, 필드 내용을 구분하는 데 필드 포함 및 구분 문자를 사용할 수 있다.

<br>

스쿱은 텍스트 파일 외에 다른 파일 포맷으로도 임포트한 데이터를 저장할 수 있다. 기본인 텍스트 파일은 사람이 판독할 수 있는 형태로 데이터를 표현하며, 플랫폼 독립적이고, 단순한 구조를 지니고 있다. 하지만 텍스트 파일은 바이너리 필드(데이터베이스의 VARBINARY 컬럼)를 가질 수 없고, (null 값의 표현을 제어하는 --null-string 임포트 옵션을 사용하더라도) null 값과 문자열 "null" 값을 갖는 문자열 필드를 구분할 수 없다.

<br>

이를 해결하기 위해 스쿱은 시퀀스 파일, 에이브로 데이터 파일, 파케이 파일을 지원한다. 이런 바이너리 포맷은 임포트 된 데이터를 가장 정확하게 표현해준다. 또한 데이터를 압축해서 저장하면서도, 동일한 파일의 다른 영역을 병렬 처리하는 맵리듀스 기능을 그대로 사용할 수 있다. 그러나 스쿱의 현재 버전은 에이브로 데이터 파일 또는 시퀀스 파일을 하이브에 로드할 수 없다. 에이브로 데이터 파일은 수동으로 하이브에 로드할 수 있으며, 파케이 데이터 파일은 스쿱을 사용해서 하이브에 바로 로드할 수 있다.

> 시퀀스 파일 : 자바 기반이 아님.

> 에이브로 데이터 파일 : 다양한 언어로 처리 가능.

> 파케이 파일 : 다양한 언어로 처리 가능.

<br>
<div align="right">

[목차로](#home1)

</div><br><br>
<a id="5"></a>

## 5. 생성된 코드
<br>

데이터베이스 테이블의 내용을 HDFS에 저장하는 것 외에도 스쿱은 로컬 디렉터리에 자바 소스(widgets.java)을 생성한다.

<br>
<div align="right">

[목차로](#home1)

</div><br><br>
<a id="6"></a>

## 6. 생성된 코드